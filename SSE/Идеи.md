# Самое главное, это составить план, как решать проблему потери соединения

> [!note|badge] 
> Максимальное упрощение (ЛУЧШЕ ТАК НЕ ДЕЛАТЬ):
> 
>  Событие error и последующий повторный запрос произойдет в двух ситуациях, если сервер перезагрузился, либо у клиента затупила сеть/поменялась на другую. В таком случае можно не заморачиваться с логикой lastEventId на сервере, а просто тупо все очистить на клиенте, закрывать экземпляр EventSource (`close()`) и создавать новый экземпляр. Только надо делать проверку, из за чего все таки произошла ошибка, потому что если из за того, что при создании нового экземпляра, сервер так и не заработал, то надо просто подождать.

# Интересно

> [!tip|badge]
> Если реализовывать двухсторонний пинг:
>  [На socket можно поставить timeout](https://nodejs.org/api/net.html#socketsettimeouttimeout-callback) (по умолчанию его нет), который сработает, если за это время в него ничего не было записано, в обработчике надо самому вызвать [`socket.end()`](https://nodejs.org/api/net.html#socketenddata-encoding-callback) или [`socket.destroy()`](https://nodejs.org/api/net.html#socketdestroyerror), чтобы закрыть соединение. Но нужен ли это пинг вообще, вряд ли.

> [!tip|badge]
> Другая ситуация - если используется nginx между клиентом и сервером, то тут уже надо пинговать с сервера nginx (потому что в nginx таймаут 60 секунд по умолчанию). Либо просто поставить очень большой таймаут в nginx для запросов на SSE.

# Реализация общего чата, несколько событий

1. Последние 500 сообщений будут храниться в кэше (в данном случае в оперативке), чтобы делать запрос к базе данных только при запуске сервера, а не при каждом запросе клиента.

> [!tip|badge]
> Используя кэш, в бд может быть любой тип столбца id, например uuid, а в кэше реализуем id как int autoincrement + таким образом клиент не увидит id сообщений из бд.

2. Чтобы загрузить эти последние 500 сообщений, клиент должен сделать запрос на ednpoint "/init". Сообщения отправляются как `{id: cachedId, value: message}`, id кэша нужен, чтобы обновлять, удалять сообщения, а в value указываем само сообщение, но исключив id из бд. По мимо сообщений, ему отправляется лимит кэша (т.е. 500), как значение лимита интерактивных сообщений на клиенте, и, если в бд 500+ сообщений, также отправляется время создания самого старого сообщения в кэше.
3. Endpoint '/history?loadFrom=timestamp' - чтобы подгрузить еще больше сообщений.

> [!tip|badge]
> Интерактивные сообщения на клиенте - это сообщения, которые можно обновлять, удалять. Логика такая - это те самые сообщения, которые на сервере содержатся в кэше - т.е. последние 500 сообщений из бд. За этим стоит идея, что вряд ли клиенту разрешается обновлять, удалять старые сообщений (500 это нормальное кол-во, никто не будет пролистывать на 500 сообщений в низ, чтобы проверить, исправил ли тот или иной пользователь опечатку в своем сообщении).

> [!warning|badge]
> По другому бы и не получилось сделать - чтобы удалить/обновить надо id из бд,  нам доступны только id сообщений, которые лежат в кэше.

4. Второй кэш - для sse событий создания/обновления/удаления сообщений. При создании - прежде чем отправить клиенту sse событие, оно кэшируется.
5. При удалении - можно удалить только сообщение, которое содержится в кэше. Событие кэшируется, отправляется клиенту, чтобы он обновил UI.
6. Если запрос на sse пришел без lastEventId, то просто добавляем пользователя в channel, ==если же lastEventId присутствует, то==:
	1. При перезагрузки сервера кэш сообщений будет заново создан, их id скорее всего будут конфликтовать с id интерактивных сообщений на клиенте. Т.е. представим ситуацию, что на клиенте 150 сообщений (лимит кэша/интерактивности пусть будет 100), если был перезагружен сервер, то новое сообщение в кэше будет иметь id 101, мы его отправляем клиенту, а там уже есть сообщение 101 и оно исходя из лимита еще интерактивное - не получится нормально удалить/обновить сообщение. Поэтому при перезагрузке сервера клиенту надо закрыть старый EventSource и создать новый экземпляр.
	2. Затем проверяем, есть ли в кэше событие с таким же id, как lastEventId или lastEventId + 1 - если нет, значит у клиента затупила сеть/поменялась на другую и за время его отсутствия какие то устаревшие события вытеснены из кэша, значит он их пропустил - поэтому тоже пусть создает новый экземпляр EventSource.
	3. Если все нормально, возвращаем события, у которых id больше, чем lastEventId.
7. Логика пинга такая же, как в реализации личного чата

# Реализация личного чата (тех. поддержка)

> [!tip|badge]
> Так как это личный чат, ничего страшного, что клиент может увидеть id сообщения из бд.

## Если бы единственным событием было создание нового сообщения

> [!tip|badge]
> Тогда не надо хранить в оперативке события - при повторном запросе просто возвращать из бд сообщения, у которых id больше, чем lastEventId (точнее формировать события на основе этих сообщений и сразу отправлять их клиенту). 

## Несколько событий 

> [!warning|badge]
> На каждый ednpoint запрос должен идти с идентификатором пользователя (например cookie с именем uid).

1. Endpoint "/history" для получения 200 последних сообщений по uid. Если в бд больше 200+ сообщений, то клиент сможет подгрузить еще больше сообщений, сделав запрос по этому же адресу, только указав в query string id самого старого, полученного им сообщения.
2. Для каждого uid будет запись в хранилище (оперативке), хранить будем массив событий и auto-increment id (его используем, для id событий). ==Эта запись будет добавлена в хранилище только после того, как произошло первое событие==, а не при самом запросе на sse. Каждые 30 минут надо будет фильтровать эти массивы, убирая из них события, которые старше 30 минут, если массив станет пустым, то вообще удалить запись по этому uid из хранилища.
3. Чтобы не спамить сообщениями, можно поставить ограничение на 1 сообщение в секунду.
4. Если запрос на sse пришел без lastEventId, то просто добавляем пользователя в channel, ==если же lastEventId присутствует, то==:
	1. Если в хранилище событий нет записи по uid, значит сервер был перезагружен (потому что как написано выше, запись в хранилище добавляется только после первого события) - клиенту надо закрыть старый EventSource и создать новый экземпляр.
	2. Затем проверяем, есть ли в массиве событие с таким же id, как lastEventId или lastEventId + 1 - если нет, значит у клиента затупила сеть/поменялась на другую и за время его отсутствия какие то устаревшие события были отфильтрованы, значит он их пропустил - поэтому тоже пусть создает новый экземпляр EventSource.
	3. Если все нормально, возвращаем события, у которых id больше, чем lastEventId.
5. При новом запросе/повторном запросе на sse, клиенту будет отправлено событие "ping", с данными - id этого запроса и интервалом, с которым нужно пинговать сервер. На клиенте код написан так, что таймаут, который используется для пинга - храниться в какой то переменной (то, что возвращает setTimeout), и если будет сделан повторный запрос, то прошлый таймаут будет сброшен (clearTimeout).


